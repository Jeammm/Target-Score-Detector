{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "![](icons/inputs.png)\n",
    "***\n",
    "# <center>Inputs</center>\n",
    "***\n",
    "\n",
    "**model**: *An image of the target at which we shoot. Should be as clean as possible and must be arrows-free.*\n",
    "<br>\n",
    "**video_name**: *The path of the video we analyze.*\n",
    "<br>\n",
    "**bullseye_point**: *An (x,y) coordinates tuple of the bull'seye location in the target image.*\n",
    "<br>\n",
    "**inner_diameter_px**: *The diameter in pixels of the most inner ring in the target image (the faded ring inside the 10 ring).*\n",
    "<br>\n",
    "**inner_diameter_in**: *The diameter in inches of the most inner ring in the target image (the faded ring inside the 10 ring).*\n",
    "<br>\n",
    "**rings_amount**: *Amount of rings in the target.*\n",
    "<br>\n",
    "**display_in_cm**: *True to display measures in centimeters instead of inches.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.imread('target.jpg')\n",
    "video_name = 'video.mp4'\n",
    "bullseye_point = (325,309)\n",
    "inner_diameter_px = 50\n",
    "inner_diameter_inch = 1.5\n",
    "rings_amount = 6\n",
    "display_in_cm = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "![](icons/preperations.png)\n",
    "***\n",
    "# <center>Preperations</center>\n",
    "***\n",
    "Calculate everything we can in advance before the analysis starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a sample frame from the video\n",
    "cap = cv2.VideoCapture(video_name)\n",
    "_, test_sample = cap.read()\n",
    "\n",
    "# calculate the sizes of the frame and the input\n",
    "model_h, model_w, _ = model.shape\n",
    "frame_h, frame_w, _ = test_sample.shape\n",
    "pixel_to_inch = inner_diameter_inch / inner_diameter_px\n",
    "pixel_to_cm = pixel_to_inch * 2.54\n",
    "measure_unit = pixel_to_cm if display_in_cm else pixel_to_inch\n",
    "measure_unit_name = 'cm' if display_in_cm else '\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a zero padded image and get its anchor points\n",
    "def _zero_pad_as(img, padding_shape):\n",
    "    img_h, img_w, _ = img.shape\n",
    "    p_h, p_w, _ = padding_shape\n",
    "    vertical = int((p_h - img_h) / 2)\n",
    "    horizontal = int((p_w - img_w) / 2)\n",
    "    a = (horizontal,vertical)\n",
    "    b = (horizontal + img_w,vertical)\n",
    "    c = (horizontal + img_w,vertical + img_h)\n",
    "    d = (horizontal,vertical + img_h)\n",
    "    e = (int(horizontal + img_w / 2),int(vertical + img_h / 2))\n",
    "    pad_img = cv2.copyMakeBorder(img, vertical, vertical, horizontal, horizontal, cv2.BORDER_CONSTANT)\n",
    "    anchor_points = [a, b, c, d, e]\n",
    "\n",
    "    return anchor_points, pad_img\n",
    "\n",
    "anchor_points, pad_model = _zero_pad_as(model, test_sample.shape)\n",
    "anchor_a = anchor_points[0]\n",
    "bullseye_anchor = (anchor_a[0] + bullseye_point[0],anchor_a[1] + bullseye_point[1])\n",
    "anchor_points.append(bullseye_anchor)\n",
    "anchor_points = np.float32(anchor_points).reshape(-1, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "model_keys, model_desc = sift.detectAndCompute(pad_model, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "![](icons/matching.png)\n",
    "***\n",
    "# <center>Feature Matching</center>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the model image and find it in the frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_match(matcher, query_desc, train, ratio):\n",
    "    train_keys, train_desc = matcher.detectAndCompute(train, None)\n",
    "    bf = cv2.BFMatcher(crossCheck=False)\n",
    "    best_match = []\n",
    "    \n",
    "    if type(train_desc) != type(None):\n",
    "        # apply ratio test\n",
    "        matches = bf.knnMatch(query_desc, train_desc, k=2)\n",
    "\n",
    "        try:\n",
    "            for m1, m2 in matches:\n",
    "                if m1.distance < ratio * m2.distance:\n",
    "                    best_match.append(m1)\n",
    "        except ValueError:\n",
    "            return [], ([], [])\n",
    "\n",
    "    return best_match, (train_keys, train_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](icons/homography.png)\n",
    "***\n",
    "# <center>Homography</center>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the homography of the target image that had been found in the frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_homography(query_keys, train_keys, matches):\n",
    "    if not len(matches):\n",
    "        return None\n",
    "\n",
    "    # reshape keypoints\n",
    "    src_pts = np.float32([query_keys[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([train_keys[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    \n",
    "    H, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the homography is realistic enough, and not TOO stretched.<br>\n",
    "This function checks the ratio between the homography edges,\n",
    "and that the vertices are in the expected 2D order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_true_homography(vertices, edges, img_size, stretch_threshold):\n",
    "    A = vertices[0]\n",
    "    B = vertices[1]\n",
    "    C = vertices[2]\n",
    "    D = vertices[3]\n",
    "    E = vertices[4]\n",
    "    upsidedown = B[0] < A[0]\n",
    "\n",
    "    if upsidedown:\n",
    "        c_ordered = C[0] < D[0] and C[1] < B[1]\n",
    "        d_ordered = D[1] < A[1]\n",
    "        e_ordered = E[0] < D[0] and E[0] > B[0]\n",
    "    else:\n",
    "        c_ordered = C[0] > D[0] and C[1] > B[1]\n",
    "        d_ordered = D[1] > A[1]\n",
    "        e_ordered = E[0] > D[0] and E[0] < B[0]\n",
    "\n",
    "    ab = edges[0]\n",
    "    bc = edges[1]\n",
    "    cd = edges[2]\n",
    "    da = edges[3]\n",
    "\n",
    "    unstretched_hor = ab / cd >= 1 - stretch_threshold and ab / cd <= 1 + stretch_threshold\n",
    "    unstretched_ver = bc / da >= 1 - stretch_threshold and bc / da <= 1 + stretch_threshold\n",
    "\n",
    "    unstretched = unstretched_hor and unstretched_ver\n",
    "    all_ordered = c_ordered and d_ordered and e_ordered\n",
    "    vals_arr = np.array([A[0],A[1],B[0],B[1],C[0],C[1],D[0],D[1],E[0],E[1]])\n",
    "    out_of_bounds = (vals_arr < 0).any() or (vals_arr > max(img_size[0], img_size[1])).any()\n",
    "\n",
    "    return unstretched and all_ordered and not out_of_bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "![](icons/2d.png)\n",
    "***\n",
    "# <center>2D Geometry Utility Calculations</center>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple eucliedean distance formula that we will be using now and then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(p1, p2):\n",
    "    return ((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2) ** .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the model image and the detected object in the frame (which are hopefully the same object), and calculate these 3 attributes:\n",
    "\n",
    "* **horizontal percentage**: *Horizontal scale ratio of the model's edges divided by the object's edges.*\n",
    "<br>\n",
    "* **vertical percentage**: *Vertical scale ratio of the model's edges divided by the object's edges.*\n",
    "<br>\n",
    "* **scale percentage**: *Average of both the horizontal and vertical scale ratios. It sheds more light on their ratio difference.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_model_scale(edges, model_shape):\n",
    "    horizontal_edge = (edges[0] + edges[2]) / 2\n",
    "    vertical_edge = (edges[1] + edges[3]) / 2\n",
    "    hor_percent = horizontal_edge / vertical_edge\n",
    "    ver_percent = vertical_edge / horizontal_edge\n",
    "    hor_scale = horizontal_edge / model_shape[1]\n",
    "    ver_scale = vertical_edge / model_shape[0]\n",
    "    scale_percent = (hor_scale + ver_scale) / 2\n",
    "\n",
    "    return hor_percent, ver_percent, scale_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the 4 coordinates and 4 edge lengths of a given rectangular transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_vertices_and_edges(transform):\n",
    "    vertices = [transform[m][0] for m in range(len(transform))]\n",
    "    A = vertices[0]\n",
    "    B = vertices[1]\n",
    "    C = vertices[2]\n",
    "    D = vertices[3]\n",
    "    ab = (((A[0] - B[0]) ** 2) + ((A[1] - B[1]) ** 2)) ** .5\n",
    "    bc = (((B[0] - C[0]) ** 2) + ((B[1] - C[1]) ** 2)) ** .5\n",
    "    cd = (((C[0] - D[0]) ** 2) + ((C[1] - D[1]) ** 2)) ** .5\n",
    "    da = (((D[0] - A[0]) ** 2) + ((D[1] - A[1]) ** 2)) ** .5\n",
    "\n",
    "    return vertices, (ab, bc, cd, da)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the euclidean distance of each pixel in the image from the target's bull'seye point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bullseye_pixels_distances(frame_size, bullseye):\n",
    "    dx = np.arange(frame_size[1])\n",
    "    dy = np.arange(frame_size[0])\n",
    "    x, y = bullseye[0], bullseye[1]\n",
    "    mat_X, mat_Y = np.meshgrid(dx, dy)\n",
    "    distances = ((mat_X, mat_Y), euclidean_dist((mat_X,mat_Y), (x,y)))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "![](icons/contours.png)\n",
    "***\n",
    "# <center>Contours Classification</center>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the distance of each pixel in a contour from a specified point, and return a sorted list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour_distances_from(contourPts, point):\n",
    "    pts = [[p[0], p[1], 0] for p in contourPts]\n",
    "    \n",
    "    for i in range(len(pts)):\n",
    "        p = pts[i]\n",
    "        xy = (p[0],p[1])\n",
    "        p[2] = euclidean_dist(xy, point)\n",
    "    \n",
    "    return sorted(pts, key=lambda x: x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extend the straight contour line owtwards the target, to try and reproduce the shape and length of the actual projectile.<br>\n",
    "This helps joining multiple contours in a row, that refer to the same projectile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_contour_line(img, contour, bullseye, length):\n",
    "    def normalize(vector):\n",
    "        square_sum = 0\n",
    "        for x in vector:\n",
    "            square_sum += x ** 2\n",
    "\n",
    "        magnitude = square_sum ** .5\n",
    "        return np.array(vector) / magnitude\n",
    "\n",
    "    # find a rectangle that strictly bounds the contour\n",
    "    bounding_rect = cv2.minAreaRect(contour)\n",
    "    box = cv2.boxPoints(bounding_rect)\n",
    "    box = np.int0(box)\n",
    "    A = box[0]\n",
    "    B = box[1]\n",
    "    C = box[2]\n",
    "    D = box[3]\n",
    "\n",
    "    # find the two shorter edges\n",
    "    AB = euclidean_dist(A, B)\n",
    "    BC = euclidean_dist(B, C)\n",
    "\n",
    "    if AB < BC:\n",
    "        edge_1_pts = (A,B)\n",
    "        edge_2_pts = (C,D)\n",
    "    else:\n",
    "        edge_1_pts = (B,C)\n",
    "        edge_2_pts = (A,D)\n",
    "\n",
    "    # calculate the middle points of the two edges\n",
    "    alpha = (int((edge_1_pts[0][0] + edge_1_pts[1][0]) / 2),int((edge_1_pts[0][1] + edge_1_pts[1][1]) / 2))\n",
    "    beta = (int((edge_2_pts[0][0] + edge_2_pts[1][0]) / 2),int((edge_2_pts[0][1] + edge_2_pts[1][1]) / 2))\n",
    "\n",
    "    # decide which edge is closer to the target's bulls'eye point\n",
    "    alpha_dist = euclidean_dist(alpha, bullseye)\n",
    "    beta_dist = euclidean_dist(beta, bullseye)\n",
    "    front_point = alpha if alpha_dist < beta_dist else beta\n",
    "    rear_point = beta if alpha_dist < beta_dist else alpha\n",
    "\n",
    "    # calculate the estimated point of the projectile's back\n",
    "    direction = normalize(np.array(rear_point) - np.array(front_point))\n",
    "    end_point = np.array(front_point) + direction * length\n",
    "    end_point = end_point.tolist()\n",
    "    end_point = tuple([int(x) for x in end_point])\n",
    "\n",
    "    cv2.line(img, front_point, end_point, (0xff,0x0,0xff), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if a contour is a rectangular or is it convexed (moon-shaped).<br>\n",
    "This helps eliminating the outlier contours that are generated from the target's rings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_contour_rect(cont, A, B, samples):\n",
    "    x_distance = B[0] - A[0]\n",
    "    y_distance = B[1] - A[1]\n",
    "    x_step = x_distance / samples\n",
    "    y_step = y_distance / samples\n",
    "\n",
    "    # contour is a very small square\n",
    "    if (x_step == 0 or y_step == 0):\n",
    "        return False\n",
    "\n",
    "    x_vals = np.arange(A[0], B[0], x_step)\n",
    "    y_vals = np.arange(A[1], B[1], y_step)\n",
    "    points = [(x,y) for x, y in zip(x_vals, y_vals)]\n",
    "\n",
    "    for p in points:\n",
    "        # check if point is outside the contour\n",
    "        if cv2.pointPolygonTest(cont, p, False) < 0:\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a list of contours and filter out all the contours with a convex shape, which are defenitely not straight projectiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_convex_contours(contours):\n",
    "    filtered = []\n",
    "\n",
    "    for cont in contours:\n",
    "        contPts = [(cont[m][0][0],cont[m][0][1]) for m in range(len(cont))]\n",
    "        point_A = contPts[0] # some random point on the contour\n",
    "\n",
    "        # find the two furthest points on the contour\n",
    "        point_B = contour_distances_from(contPts, point_A)[::-1][0]\n",
    "        point_A = contour_distances_from(contPts, point_B)[::-1][0]\n",
    "\n",
    "        # calculate the point between the two\n",
    "        point_C = ((point_A[0] + point_B[0]) / 2, (point_A[1] + point_B[1]) / 2)\n",
    "\n",
    "        # if this point is outside the contour, it's convex,\n",
    "        # if it's inside it, the contour is relatively straight\n",
    "        if is_contour_rect(cont, point_A, point_B, 5):\n",
    "            filtered.append(cont)\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "![](icons/compvis.png)\n",
    "***\n",
    "# <center>Visual Analysis</center>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take both the model image and the detected object in the frame and perform a background subtraction,<br>\n",
    "idealy creating in an image of the arrows alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_background(query, subtrahend):\n",
    "    # convert to grayscale\n",
    "    gray_query = cv2.cvtColor(query, cv2.COLOR_RGB2GRAY)\n",
    "    gray_subtrahend = cv2.cvtColor(subtrahend, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # apply gaussian blur\n",
    "    kernel = (3,3)\n",
    "    gray_query = cv2.GaussianBlur(gray_query, kernel, 0)\n",
    "    gray_subtrahend = cv2.GaussianBlur(gray_subtrahend, kernel, 0)\n",
    "\n",
    "    # apply a black area on the subtrahend image\n",
    "    gray_subtrahend[gray_query == 0] = 0\n",
    "\n",
    "    # calculate diff\n",
    "    diff = cv2.absdiff(gray_subtrahend, gray_query)\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emphasize all of the straight lines in the image and get rid of unnecessary noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emphasize_lines(img, distances, estimated_radius):\n",
    "    # find the target's outer ring\n",
    "    circles = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT, 1, 20,\n",
    "                               param1=50, param2=30, minRadius=0,\n",
    "                               maxRadius=int(estimated_radius * 1.05))\n",
    "    \n",
    "    # use largest detected circle\n",
    "    if type(circles) != type(None):\n",
    "        outerCircle = sorted(circles[0], key=lambda x: x[2])[::-1][0]\n",
    "        radius = outerCircle[2]\n",
    "        \n",
    "    # use a rough estimation of the target's radius as a fallback\n",
    "    else:\n",
    "        radius = estimated_radius\n",
    "\n",
    "    # zero out all pixels outside of the outer ring\n",
    "    img[distances[1] > radius] = 0\n",
    "    \n",
    "    # apply thresh and morphology\n",
    "    _, img = cv2.threshold(img, 20, 0xff, cv2.THRESH_BINARY)\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
    "\n",
    "    # find the straight segments in the image\n",
    "    lines = cv2.HoughLinesP(img, 2, np.pi / 180, 120, minLineLength=20, maxLineGap=0)\n",
    "    img_copy = np.zeros(img.shape, dtype=img.dtype)\n",
    "\n",
    "    if type(lines) != type(None):\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                cv2.line(img_copy, (x1, y1), (x2, y2), (0xff,0xff,0xff), 5)\n",
    "                \n",
    "    return radius, img_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extend the emphasized lines outwards the target circle in order to restore the shape of the projectiles that might have been broken during the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproduce_projectile_contours(img, distances, bullseye, radius):\n",
    "    # detect the unconvex contours (true projectile contours)\n",
    "    contours = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)[-2:]\n",
    "    rect_contours = filter_convex_contours(contours[0])\n",
    "    blank_img = np.zeros(img.shape, dtype=img.dtype)\n",
    "    \n",
    "    for cont in rect_contours:\n",
    "        extend_contour_line(blank_img, cont, bullseye, length=radius)\n",
    "    \n",
    "    # clear unnecessary noise\n",
    "    blank_img[distances[1] > radius] = 0\n",
    "    blank_img = cv2.morphologyEx(blank_img, cv2.MORPH_CLOSE, np.ones((3,3), np.uint8))\n",
    "    \n",
    "    # detect contours again, after the extension\n",
    "    return cv2.findContours(blank_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)[-2:][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume all the contours that are left are indeed projectiles, and calculate the distances of their pointy edges from the target's bull'seye point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_suspect_hits(contours, vertices, scale):\n",
    "    bullseye = vertices[5]\n",
    "    res = []\n",
    "    \n",
    "    for cont in contours:\n",
    "        contPts = [(cont[m][0][0],cont[m][0][1]) for m in range(len(cont))]\n",
    "        point_A = contPts[0] # some random point on the contour\n",
    "\n",
    "        # find the two furthest points on the contour\n",
    "        point_B = contour_distances_from(contPts, point_A)[::-1][0]\n",
    "        point_A = contour_distances_from(contPts, point_B)[::-1][0]\n",
    "        \n",
    "        # decide which of them is closer to the bullseye point\n",
    "        A_dist = euclidean_dist(point_A, bullseye)\n",
    "        B_dist = euclidean_dist(point_B, bullseye)\n",
    "        hit = point_A if A_dist < B_dist else point_B\n",
    "\n",
    "        # straighten the target's oval and find the real hit values\n",
    "        res_x = (hit[0] - vertices[0][0]) * scale[0] + vertices[0][0]\n",
    "        res_y = (hit[1] - vertices[0][1]) * scale[1] + vertices[0][1]\n",
    "        res_dist = euclidean_dist(hit, bullseye)\n",
    "        res_hit = (res_x,res_y,res_dist, bullseye)\n",
    "        res.append(res_hit)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "![](icons/detection.png)\n",
    "***\n",
    "# <center>Score Detection System</center>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is necessary to design a customized class for detected hits.\n",
    "\n",
    "**point**: *The (x,y) coordinates of the hit.*\n",
    "<br>\n",
    "**score**: *The calculated score of the hit according to the rules.*\n",
    "<br>\n",
    "**reputation**: *The consistency of the hit over the frames.<br>\n",
    "A hit with high reputation means it has been detected over and over again over multiple consistent frames.*\n",
    "<br>\n",
    "**bullseye_relation**: *The bull'seye coordinates of the target from the last time the hit had been detected.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hit:\n",
    "    def __init__(self, x, y, score, bullseyeRelation):\n",
    "        self.point = (x, y)\n",
    "        self.score = score\n",
    "        self.reputation = 1\n",
    "        self.bullseye_relation = bullseyeRelation\n",
    "        \n",
    "        # has this hit been checked during current iteration\n",
    "        self.iter_mark = False\n",
    "    \n",
    "    def increase_rep(self):\n",
    "        self.reputation += 1\n",
    "        \n",
    "    def decrease_rep(self):\n",
    "        self.reputation -= 1\n",
    "        \n",
    "    def isVerified(self, repScore):\n",
    "        return self.reputation >= repScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score calculation\n",
    "![10 rings target](images/fita_target.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_score(hits, scale):\n",
    "    scoreboard = []\n",
    "    \n",
    "    for hit in hits:\n",
    "        hit_dist = hit[2]\n",
    "        scaled_diam = inner_diameter_px * scale[2]\n",
    "        score = 10 - int(hit_dist / scaled_diam)\n",
    "\n",
    "        # clamp score between 10 and minimum available score\n",
    "        if score < 10 - rings_amount + 1:\n",
    "            score = 0\n",
    "        elif score > 10:\n",
    "            score = 10\n",
    "        \n",
    "        hit_obj = Hit(int(hit[0]), int(hit[1]), score, hit[3])\n",
    "        scoreboard.append(hit_obj)\n",
    "\n",
    "    return scoreboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, we need 2 lists:\n",
    "* A list for candidate hits, that are not yet confirmed to be real\n",
    "* A list for verified confirmed hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_hits = []\n",
    "verified_hits = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a way to search within those lists and check if each of the hits we detect is already known.<br>\n",
    "**distanceTolerance** is a parameter that allows us to indentify a detected hit in the lists, even if it is no longer located at the exact coordinates as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_verified_hit(point, distanceTolerance):\n",
    "    return type(get_verified_hit(point, distanceTolerance)) != type(None)\n",
    "\n",
    "def is_candidate_hit(point, distanceTolerance):\n",
    "    return type(get_candidate_hit(point, distanceTolerance)) != type(None)\n",
    "\n",
    "def get_verified_hit(point, distanceTolerance):\n",
    "    compatible_hits = []\n",
    "    \n",
    "    for hit in verified_hits:\n",
    "        if euclidean_dist(point, hit.point) <= distanceTolerance:\n",
    "            compatible_hits.append(hit)\n",
    "            \n",
    "    if len(compatible_hits) > 0:\n",
    "        return compatible_hits[0]\n",
    "    else:\n",
    "        return None;\n",
    "\n",
    "def get_candidate_hit(point, distanceTolerance):\n",
    "    compatible_hits = []\n",
    "    \n",
    "    for hit in candidate_hits:\n",
    "        if euclidean_dist(point, hit.point) <= distanceTolerance:\n",
    "            compatible_hits.append(hit)\n",
    "            \n",
    "    if len(compatible_hits) > 0:\n",
    "        return compatible_hits[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find duplicate verified hits and eliminate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminateVerifiedRedundancy(distanceTolerance):\n",
    "    if len(verified_hits) <= 1:\n",
    "        return\n",
    "    \n",
    "    # create a table of the distances between all hits\n",
    "    table = np.ndarray((len(verified_hits),len(verified_hits)), np.float32)\n",
    "    j_leap = 0\n",
    "    for i in range(len(table)):\n",
    "        for j in range(len(table[i])):\n",
    "            col = j + j_leap\n",
    "            if col >= len(table[i]):\n",
    "                continue\n",
    "            \n",
    "            hit_i = verified_hits[i].point\n",
    "            hit_j = verified_hits[col].point\n",
    "            dist = euclidean_dist(hit_i, hit_j)\n",
    "            table[i][col] = dist\n",
    "            \n",
    "        j_leap += 1\n",
    "    \n",
    "    # find distances that are smaller than the threshold and eliminate the redundant hits\n",
    "    j_leap = 0\n",
    "    for i in range(len(table)):\n",
    "        for j in range(len(table[i])):\n",
    "            col = j + j_leap\n",
    "            if col >= len(verified_hits):\n",
    "                continue\n",
    "            \n",
    "            if i == col or i >= len(verified_hits):\n",
    "                continue\n",
    "            \n",
    "            if table[i][col] < distanceTolerance:\n",
    "                hit_i = verified_hits[i].point\n",
    "                hit_j = verified_hits[col].point\n",
    "                \n",
    "                # check the distance from the bull'seye point\n",
    "                bullseye_i = verified_hits[i].bullseye_relation\n",
    "                bullseye_j = verified_hits[col].bullseye_relation\n",
    "                bullseye_dist_i = euclidean_dist(hit_i, bullseye_i)\n",
    "                bullseye_dist_j = euclidean_dist(hit_j, bullseye_j)\n",
    "\n",
    "                if bullseye_dist_i < bullseye_dist_j:\n",
    "                    verified_hits.remove(verified_hits[col])\n",
    "                else:\n",
    "                    verified_hits.remove(verified_hits[i])\n",
    "        \n",
    "        j_leap += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting a newly detected hit\n",
    "\n",
    "* <font color='green'><u>Already verified</u></font> - Don't change it.<br><br>\n",
    "\n",
    "* <font color='red'><u>Already a candidate</u></font> - Increase its reputation.<br>\n",
    "A candidate hit with enough reputation becomes verified.<br><br>\n",
    "\n",
    "* <u>Unfamiliar</u> - Add it to the candidates list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_hit(hit, distanceTolerance, maxReputation):\n",
    "    candidate = get_candidate_hit(hit.point, distanceTolerance)\n",
    "\n",
    "    # the hit is a known candidate\n",
    "    if type(candidate) != type(None):\n",
    "        candidate.increase_rep()\n",
    "        candidate.iter_mark = True\n",
    "\n",
    "        # candidate is now eligable for verification\n",
    "        if candidate.isVerified(maxReputation):\n",
    "            verified_hits.append(candidate)\n",
    "            candidate_hits.remove(candidate)\n",
    "            \n",
    "            # find duplicate verified hits and eliminate them\n",
    "            eliminateVerifiedRedundancy(distanceTolerance)\n",
    "\n",
    "    # new candidate\n",
    "    else:\n",
    "        candidate_hits.append(hit)\n",
    "        hit.iter_mark = True        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disqualifying candidate hits\n",
    "The hits the are listed as candidates, but not detected during the last frame, have their reputation decreased.<br>\n",
    "A reputation lower than 0 causes the removal of the hit from the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discharge_hits():\n",
    "    for candidate in candidate_hits:\n",
    "        # candidate is not present during the current iteration\n",
    "        if not candidate.iter_mark:\n",
    "            candidate.decrease_rep()\n",
    "            \n",
    "            # candidate disqualified\n",
    "            if candidate.reputation <= 0:\n",
    "                candidate_hits.remove(candidate)\n",
    "                continue\n",
    "        \n",
    "        # get ready for the next iteration\n",
    "        candidate.iter_mark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stabilizing hits during video movements\n",
    "Shift each hit back to its correct location, relative to the bull'seye point in the current frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_hits(bullseye):\n",
    "    all_hits = candidate_hits + verified_hits\n",
    "    \n",
    "    for h in all_hits:\n",
    "        # find the correct translation amount\n",
    "        x_dist = bullseye[0] - h.bullseye_relation[0]\n",
    "        y_dist = bullseye[1] - h.bullseye_relation[1]\n",
    "        new_x = int(round(h.point[0] + x_dist))\n",
    "        new_y = int(round(h.point[1] + y_dist))\n",
    "        \n",
    "        # translate and update relation attribute\n",
    "        h.bullseye_relation = bullseye\n",
    "        h.point = (new_x,new_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "![](icons/grouping.png)\n",
    "***\n",
    "# <center>Grouping Detection</center>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the group polygon we first need to draw the lines between all verified hits.<br>Then we take the contour of the shape that has been created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_group_polygon(img, hits):\n",
    "    blank_img = np.zeros(img.shape, dtype=img.dtype)\n",
    "    blank_img = cv2.cvtColor(blank_img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # draw lines between all hits\n",
    "    for h1 in hits:\n",
    "        for h2 in hits:\n",
    "            if h1 != h2:\n",
    "                cv2.line(blank_img, h1.point, h2.point, (0xff,0xff,0xff), 3)\n",
    "    \n",
    "    # find external contour\n",
    "    contours = cv2.findContours(blank_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[-2:]\n",
    "    blank_img = cv2.cvtColor(blank_img, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    if len(contours[0]) > 0:\n",
    "        return contours[0][0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A group of arrows is measured by the distance of the two points that are furthest apart.<br>\n",
    "The lower this distance is, the more valuable is the grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_grouping_diameter(contour):\n",
    "    # find two furthest points in the polygon\n",
    "    contPts = [(contour[m][0][0],contour[m][0][1]) for m in range(len(contour))]\n",
    "    point_A = contPts[0] # random point\n",
    "    point_B = contour_distances_from(contPts, point_A)[::-1][0]\n",
    "    point_A = contour_distances_from(contPts, point_B)[::-1][0]\n",
    "    \n",
    "    # find their distance for each other\n",
    "    point_A = (point_A[0], point_A[1])\n",
    "    point_B = (point_B[0], point_B[1])\n",
    "    return euclidean_dist(point_A, point_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](icons/mark.png)\n",
    "***\n",
    "# <center>Data Drawing</center>\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_hits(img, hits, foreground, diam, withOutline, withScore):\n",
    "    outline = (0x0,0x0,0x0)\n",
    "    \n",
    "    for hit in hits:\n",
    "        x, y = hit.point[0], hit.point[1]\n",
    "        score_string = str(hit.score) if (hit.score > 0) else 'miss'\n",
    "        \n",
    "        if withOutline:\n",
    "            cv2.circle(img, (x,y), 13, outline, diam + 2)\n",
    "            \n",
    "        cv2.circle(img, (x,y), 10, foreground, diam)\n",
    "        \n",
    "        if withScore:\n",
    "            cv2.putText(img, score_string, (x,y - 20), cv2.FONT_HERSHEY_PLAIN, 5, outline, thickness=15)\n",
    "            cv2.putText(img, score_string, (x,y - 20), cv2.FONT_HERSHEY_PLAIN, 5, (0xff,0xff,0xff), thickness=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_grouping(img, contour):\n",
    "    cv2.drawContours(img, contour, -1, (214,215,97), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the rectangle on which we display the overall data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_meta_data_block(img):\n",
    "    img_h, img_w, _ = img.shape\n",
    "    \n",
    "    rect_0_start = (int(img_w * .5), int(img_h * .85))\n",
    "    rect_0_end = (img_w, img_h)\n",
    "    cv2.rectangle(img, rect_0_start, rect_0_end, (0xff,0xff,0xff), -1)\n",
    "    \n",
    "    rect_1_start = (rect_0_start[0] - 60, int(img_h * .85))\n",
    "    rect_1_end = (rect_0_start[0] - 15, img_h)\n",
    "    cv2.rectangle(img, rect_1_start, rect_1_end, (0x28,0x28,0x28), -1)\n",
    "    \n",
    "    rect_2_start = (rect_1_start[0] - 50, int(img_h * .85))\n",
    "    rect_2_end = (rect_1_start[0] - 15, img_h)\n",
    "    cv2.rectangle(img, rect_2_start, rect_2_end, (248,138,8), -1)\n",
    "    \n",
    "    rect_3_start = (rect_2_start[0] - 40, int(img_h * .85))\n",
    "    rect_3_end = (rect_2_start[0] - 15, img_h)\n",
    "    cv2.rectangle(img, rect_3_start, rect_3_end, (66,0x0,0xff), -1)\n",
    "    \n",
    "    rect_4_start = (rect_3_start[0] - 30, int(img_h * .85))\n",
    "    rect_4_end = (rect_3_start[0] - 15, img_h)\n",
    "    cv2.rectangle(img, rect_4_start, rect_4_end, (0x0,204,0xff), -1)\n",
    "    \n",
    "    rect_5_start = (rect_4_start[0] - 20, int(img_h * .85))\n",
    "    rect_5_end = (rect_4_start[0] - 15, img_h)\n",
    "    cv2.rectangle(img, rect_5_start, rect_5_end, (0x0,204,0xff), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_arrows_amount(img, amount, dataColor):\n",
    "    amount = str(amount)\n",
    "    img_h, img_w, _ = img.shape\n",
    "    cv2.putText(img, 'Arrows shot: ', (int(img_w * .52), int(img_h * .905)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.4, (0x0,0x0,0x0), 4)\n",
    "    \n",
    "    cv2.putText(img, amount, (int(img_w * .675), int(img_h * .905)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.4, dataColor, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_grouping_diameter(img, diameter, dataColor):\n",
    "    diameter = str(round(diameter * measure_unit, 1))\n",
    "    img_h, img_w, _ = img.shape\n",
    "    cv2.putText(img, 'Grouping: ', (int(img_w * .77), int(img_h * .905)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.4, (0x0,0x0,0x0), thickness=4)\n",
    "    \n",
    "    cv2.putText(img, diameter + measure_unit_name, (int(img_w * .89), int(img_h * .905)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.4, dataColor, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_total_score(img, totalScore, achievableScore, dataColor):\n",
    "    totalScore = str(totalScore)\n",
    "    achievableScore = str(achievableScore)\n",
    "    score_digits = len(totalScore)\n",
    "    score_space = 23 * (score_digits - 1)\n",
    "    img_h, img_w, _ = img.shape\n",
    "    \n",
    "    cv2.putText(img, 'Total score: ', (int(img_w * .52), int(img_h * .975)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.4, (0x0,0x0,0x0), thickness=4)\n",
    "    \n",
    "    cv2.putText(img, totalScore, (int(img_w * .67), int(img_h * .975)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.4, dataColor, 4)\n",
    "    \n",
    "    cv2.putText(img, '/ ' + achievableScore, (int(img_w * .695 + score_space), int(img_h * .975)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.4, (0x0,0x0,0x0), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](icons/film.png)\n",
    "***\n",
    "# <center>Video Analysis</center>\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(frame):\n",
    "    # set default analysis meta-data\n",
    "    scoreboard = []\n",
    "    scores = []\n",
    "    bullseye_point = None\n",
    "\n",
    "    # find a match between the model image and the frame\n",
    "    matches, (train_keys, train_desc) = ratio_match(sift, model_desc, frame, .7)\n",
    "\n",
    "    # start calculating homography\n",
    "    if len(matches) >= 4:\n",
    "        homography = calc_homography(model_keys, train_keys, matches)\n",
    "\n",
    "        # check if homography succeeded and start warping the model over the detected object\n",
    "        if type(homography) != type(None):\n",
    "            warped_transform = cv2.perspectiveTransform(anchor_points, homography)\n",
    "            warped_vertices, warped_edges = calc_vertices_and_edges(warped_transform)\n",
    "            bullseye_point = warped_vertices[5]\n",
    "\n",
    "            # check if homography is good enough to continue\n",
    "            if is_true_homography(warped_vertices, warped_edges, (frame_w, frame_h), .2):\n",
    "                # warp the input image over the filmed object and calculate the scale difference\n",
    "                warped_img = cv2.warpPerspective(pad_model, homography, (frame_w, frame_h))\n",
    "                scale = calc_model_scale(warped_edges, model.shape)\n",
    "                \n",
    "                # process image\n",
    "                sub_target = subtract_background(warped_img, frame)\n",
    "                pixel_distances = calc_bullseye_pixels_distances(frame.shape, warped_vertices[5])\n",
    "                estimated_warped_radius = rings_amount * inner_diameter_px * scale[2]\n",
    "                circle_radius, emphasized_lines = emphasize_lines(sub_target, pixel_distances,\n",
    "                                                                  estimated_warped_radius)\n",
    "                \n",
    "                proj_contours = reproduce_projectile_contours(emphasized_lines, pixel_distances,\n",
    "                                                              warped_vertices[5], circle_radius)\n",
    "                \n",
    "                suspect_hits = find_suspect_hits(proj_contours, warped_vertices, scale)\n",
    "\n",
    "                # calculate hits and draw circles around them\n",
    "                scoreboard = calc_score(suspect_hits, scale)\n",
    "\n",
    "    return bullseye_point, scoreboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') # DIVX, XVID, MJPG, X264, WMV1, WMV2,...\n",
    "out = cv2.VideoWriter('output.mp4',fourcc, 24.0, (frame_w,frame_h))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        bullseye, scoreboard = analyze(frame)\n",
    "        \n",
    "        # increase reputation of consistent hits\n",
    "        # or add them as new candidates\n",
    "        for hit in scoreboard:\n",
    "            sort_hit(hit, 30, 15)\n",
    "        \n",
    "        # decrease reputation of inconsistent hits\n",
    "        discharge_hits()\n",
    "        \n",
    "        # stabilize all hits according to the slightly shifted bull'seye point\n",
    "        if type(bullseye) != type(None):\n",
    "            shift_hits(bullseye)\n",
    "            \n",
    "        # extract grouping data\n",
    "        grouping_contour = create_group_polygon(frame, verified_hits)\n",
    "        has_group = type(grouping_contour) != type(None)\n",
    "        grouping_diameter = measure_grouping_diameter(grouping_contour) if has_group else 0\n",
    "            \n",
    "        # write meta data on frame\n",
    "        draw_meta_data_block(frame)\n",
    "        verified_scores = [h.score for h in verified_hits]\n",
    "        arrows_amount = len(verified_scores)\n",
    "        type_arrows_amount(frame, arrows_amount, (0x0,0x0,0xff))\n",
    "        type_total_score(frame, sum(verified_scores), arrows_amount * 10, (0x0,189,62))\n",
    "        type_grouping_diameter(frame, grouping_diameter, (0xff,133,14))\n",
    "        \n",
    "        \n",
    "        # mark hits and grouping\n",
    "        draw_grouping(frame, grouping_contour)\n",
    "        mark_hits(frame, candidate_hits, foreground=(0x0,0x0,0xff),\n",
    "                  diam=2, withOutline=False, withScore=False)\n",
    "        \n",
    "        mark_hits(frame, verified_hits, foreground=(0x0,0xff,0x0),\n",
    "                  diam=5, withOutline=True, withScore=True)\n",
    "        \n",
    "        # display\n",
    "        frame_resized = cv2.resize(frame, (1153, 648))\n",
    "        cv2.imshow('Analysis', frame_resized)\n",
    "        \n",
    "        # write frame to output file\n",
    "        out.write(frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xff == 27:\n",
    "            break\n",
    "    else:\n",
    "        print('Video stream is over.')\n",
    "        break\n",
    "        \n",
    "# close window properly\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
